# =============================================================================
# INTELLIGENCE ANALYZER - PRODUCTION DOCKER COMPOSE
# =============================================================================
# Architecture: Multi-queue Redis → Worker Pool → PostgreSQL (Partitioned)
# Designed for: 10+ devices/tenant × 1,000+ logs/min/device
# =============================================================================

services:
  # ===========================================================================
  # PostgreSQL Database (Primary Storage)
  # ===========================================================================
  # Time-partitioned tables with Row-Level Security for tenant isolation
  # ===========================================================================
  postgres:
    image: postgres:15-alpine
    container_name: siem-postgres
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: siem_user
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-siem_secure_password_2026}
      POSTGRES_DB: siem_db
    volumes:
      - pg_data:/var/lib/postgresql/data
      # Init scripts for partitioning and RLS setup
      - ./scripts/init_db.sql:/docker-entrypoint-initdb.d/01_init.sql:ro
    restart: unless-stopped
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U siem_user -d siem_db" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    # Performance tuning for high-volume writes
    command: >
      postgres -c shared_buffers=256MB -c effective_cache_size=768MB -c maintenance_work_mem=128MB -c checkpoint_completion_target=0.9 -c wal_buffers=16MB -c default_statistics_target=100 -c random_page_cost=1.1 -c effective_io_concurrency=200 -c work_mem=16MB -c min_wal_size=1GB -c max_wal_size=4GB -c max_connections=200

  # ===========================================================================
  # Redis Queue & State Store
  # ===========================================================================
  # Queues: dead_logs, ingest_logs, clean_logs
  # State: bf:* (brute force), ps:* (port scan), bc:* (beaconing)
  # ===========================================================================
  redis:
    image: redis:7-alpine
    container_name: siem-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
      - ./config/redis.conf:/usr/local/etc/redis/redis.conf:ro
    restart: unless-stopped
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      interval: 10s
      timeout: 5s
      retries: 5
    # Memory limit with LRU eviction for state keys (not queues)
    command: >
      redis-server --appendonly yes --maxmemory 2gb --maxmemory-policy allkeys-lru --save 60 1000 --tcp-keepalive 300

  # ===========================================================================
  # Intelligence Analyzer API
  # ===========================================================================
  # FastAPI server for dashboards, alerts, and management
  # ===========================================================================
  analyzer:
    build:
      context: .
      target: production
    image: intelligence-analyzer:latest
    container_name: siem-analyzer
    ports:
      - "8000:8000"
    environment:
      # Database: PostgreSQL with connection pooling
      - DATABASE_URL=postgresql://siem_user:${POSTGRES_PASSWORD:-siem_secure_password_2026}@postgres:5432/siem_db
      - SQLALCHEMY_POOL_SIZE=20
      - SQLALCHEMY_MAX_OVERFLOW=10
      - SQLALCHEMY_POOL_RECYCLE=1800
      # Redis connection (pointing to host for external Redis)
      - REDIS_URL=${REDIS_URL:-redis://host.docker.internal:6379/0}
      # Queue names (matching Repo1 output)
      - REDIS_DEAD_QUEUE=dead_logs
      - REDIS_INGEST_QUEUE=ingest_logs
      - REDIS_CLEAN_QUEUE=clean_logs
      # Security
      - SECRET_KEY=${SECRET_KEY:-your-production-secret-key-change-me}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - ALLOWED_ORIGINS=${ALLOWED_ORIGINS:-http://localhost:8000}
    volumes:
      - ../reports:/app/reports
      - ../logs:/app/logs
    depends_on:
      postgres:
        condition: service_healthy
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8000/health/live" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s

  # ===========================================================================
  # Redis Consumer Workers (Log Processing Pipeline)
  # ===========================================================================
  # Consumes from: dead_logs, ingest_logs, clean_logs
  # Batch inserts to PostgreSQL (100 logs per batch)
  # Uses Redis for real-time threat detection state
  # ===========================================================================
  consumer:
    build:
      context: ..
      dockerfile: docker/Dockerfile.production
    image: intelligence-analyzer:latest
    # Note: container_name removed to allow horizontal scaling with deploy.replicas
    environment:
      # Database: PostgreSQL
      - DATABASE_URL=postgresql://siem_user:${POSTGRES_PASSWORD:-siem_secure_password_2026}@postgres:5432/siem_db
      - SQLALCHEMY_POOL_SIZE=10
      - SQLALCHEMY_MAX_OVERFLOW=5
      # Redis connection
      - REDIS_URL=${REDIS_URL:-redis://host.docker.internal:6379/0}
      # Queue names
      - REDIS_DEAD_QUEUE=dead_logs
      - REDIS_INGEST_QUEUE=ingest_logs
      - REDIS_CLEAN_QUEUE=clean_logs
      # Worker settings
      - BATCH_SIZE=100
      - BATCH_TIMEOUT_MS=1000
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    volumes:
      - ../logs:/app/logs
    depends_on:
      postgres:
        condition: service_healthy
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped
    # Scale horizontally: docker-compose up -d --scale consumer=10
    deploy:
      replicas: ${CONSUMER_REPLICAS:-2}
    command: python -m src.services.redis_consumer

# =============================================================================
# Persistent Volumes
# =============================================================================
volumes:
  pg_data:
    driver: local
  redis_data:
    driver: local

# =============================================================================
# Network
# =============================================================================
networks:
  default:
    name: siem-network
